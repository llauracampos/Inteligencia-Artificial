# -*- coding: utf-8 -*-
"""Questão_4_regressão.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17BZ2CXX4OfCepbLto6qQHlwDY8gRjyqz
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import preprocessing
from sklearn import utils
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_regression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neighbors import KNeighborsClassifier

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

data = pd.read_csv("drinking_water_potability.csv")
print(data)

#Tratamento de dados
data_zero = data.fillna(0, inplace=False)
print(data_zero)

#Normalização da base de dados
normalized_dataset = MinMaxScaler().fit_transform(data_zero) 
print(normalized_dataset)

#Adição de rotulos

data_labels = pd.DataFrame(normalized_dataset, columns=['ph','Hardness','Solids','Chloramines','Sulfate','Conductivity','Organic_carbon','Trihalomethanes','Turbidity','Potability']) 
print(data_labels)

#Separação dos atributos

array_x = np.array(data_labels.drop('Potability',1))
array_y = np.array(data_labels['Potability'])

print(array_x)
print(array_y)

#Divisão da base de dados em tratamento e teste

X = array_x
y = array_y

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30, random_state=0)

#K-NN

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30, random_state=0)

n = 15

for i in range(5):
  clf = KNeighborsRegressor(n_neighbors = n, algorithm = "kd_tree", metric='manhattan')
  clf.fit(X_train, y_train)
  y_pred = clf.predict(X_test)
  print("K = ", n)
  #R-Quadrado
  R2 = r2_score(y_test,y_pred) 
  print("R-Quadrado: ", R2)
  #Erro Quadrático Médio 
  MSE = mean_squared_error(y_test,y_pred)
  print("Erro Quadrático Médio: ", MSE)
  #Erro Absoluto Médio 
  MAE = mean_absolute_error(y_test,y_pred)
  print("Erro Absoluto Médio: ", MAE)
  n = n + 15

#K-NN

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30, random_state=0)

n = 15

for i in range(5):
  clf = KNeighborsRegressor(n_neighbors = n, algorithm = "ball_tree", metric='euclidean')
  clf.fit(X_train, y_train)
  y_pred = clf.predict(X_test)
  print("K = ", n)
  #R-Quadrado
  R2 = r2_score(y_test,y_pred) 
  print("R-Quadrado: ", R2)
  #Erro Quadrático Médio 
  MSE = mean_squared_error(y_test,y_pred)
  print("Erro Quadrático Médio: ", MSE)
  #Erro Absoluto Médio 
  MAE = mean_absolute_error(y_test,y_pred)
  print("Erro Absoluto Médio: ", MAE)
  n = n + 15